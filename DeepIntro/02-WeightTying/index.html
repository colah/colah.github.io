<!doctype html>
<html lang="en">

  <head>
    <meta charset="utf-8">

    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    <title>Weight Tying and Architecture</title>

    <meta name="description" content="This talk tries to get at the deep questions of deep learning: What is the problem we are really trying to solve? What is interesting about deep models?">
    <meta name="author" content="Chris Olah">

    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <link rel="stylesheet" href="css/reveal.min.css">
    <link rel="stylesheet" href="css/theme/simple.css" id="theme">

    <!-- For syntax highlighting -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- If the query includes 'print-pdf', include the PDF print sheet -->
    <script>
      if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = 'css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
      }
    </script>

    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
  </head>

  <body>

    <div class="reveal">

      <!-- Any section element inside of this container is displayed as a slide -->
      <div class="slides">
        <section>
          <h2>Weight-Tying & Architecture</h2>
          <br>
          <h3>DeepIntro</h3>
        </section>

        <section>
          <h2>Fully Connected Layers</h2>
          <br>
          <p>Every neuron connects to every input</p>
        </section>

        <section>
          <h2>Modules</h2>
          <br>
          <p>Simple chunks of neural net.</p>
          <br>
          <p>One or more fully-connected layers.</p>
        </section>

        <section>
          <h2>Weight-Tying</h2>
          <br>
          <p>Use copies of one neuron in multiple places.</p>
          <br>
          <p>Like functions in programming.</p>
        </section>

        <section>
          <h2>Interesting Architectures</h2>
          <br>
          <p>Weight-tying is the fundamental trick that allows us to build interesting neural network architectures.</p>
        </section>


        <section>
          <h2>Convolutional Neural Networks</h2>
        </section>


        <section>
          <h2>One Dimensional Input</h2>
          <br>
          <p><img src="imgs/Conv-9-xs.png"></p>
          <br>
          <p>(eg. Audio)</p>
        </section>


        <section>
          <h2>A Fully Connected Model</h2>
          <br>
          <p><img src="imgs/Conv-9-F.png"></p>
        </section>

        <section>
          <h2>One Dimensional Conv Nets</h2>
          <br>
          <p><img src="imgs/Conv-9-Conv2.png"></p>
          <br>
          <p>Exploit a symmetry in the features it is useful to look at.</p>
        </section>

        <section>
          <h2>One Dimensional Conv Nets</h2>
          <br>
          <p><img src="imgs/Conv-9-Conv3.png"></p>
          <br>
          <p>Looking at 3 patches.</p>
        </section>

        <section>
          <h2>One Dimensional Conv Nets</h2>
          <br>
          <p><img src="imgs/Conv-9-Conv2Conv2.png"></p>
          <br>
          <p>We can stack these layers.</p>
        </section>

        <section>
          <h2>Max Pooling</h2>
          <br>
          <p><img src="imgs/Conv-9-Conv2Max2Conv2.png"></p>
          <br>
          <p>Zoom out.</p>
        </section>


        <section>
          <p><img style="float:right; width:35%;" src="imgs/Conv2-unit.png"></p>
          <br><br>
          <h3>Two-Dimensional Conv Nets</h3>
        </section>

        <section>
          <h2>One Convolutional Layer</h2>
          <br>
          <p><img src="imgs/Conv2-9x5-Conv2.png"></p>
          <br>
          <p></p>
        </section>


        <section>
          <h2>Two Convolutional Layers</h2>
          <br>
          <p><img src="imgs/Conv2-9x5-Conv2Conv2.png"></p>
          <br>
          <p></p>
        </section>

        <section>
          <h2>Two Conv Layers with Max Pooling Layer</h2>
          <p><img src="imgs/Conv2-9x5-Conv2Max2Conv2.png"></p>
        </section>


        <section>
          <h2>Inside A</h2>
          <br>
          <p><img src="imgs/Conv-A.png"></p>
          <br>
          <p>In a normal convolutional layer.</p>
        </section>


        <section>
          <h2>Inside A (Network In Network)</h2>
          <br>
          <p><img src="imgs/Conv-A-NIN.png"></p>
          <br>
          <p>In an "MLP conv layer" or "network in network" model.</p>
        </section>


        <section>
          <h2>Example: Krizhevsky</h2>
          <br>
          <p><img src="imgs/KSH-arch.png"></p>
          <br>
          <p>Lots of ingredients to make this work!</p>
        </section>

        <section>
          <h2>Example: Krizhevsky</h2>
          <br>
          <p><img src="imgs/KSH-results.png"></p>
          <br>
          <p>Kirzhevksy, <i>et al.</i> (2012); 85% top-5 accuracy</p>
        </section>

        <section>
          <h2>Example: Inception</h2>
          <br>
          <p>96% top-5 accuracy</p>
        </section>


        <section>
          <h2>Recurrent Neural Networks</h2>
        </section>


        <section>
          <h2>Recurrent Neural Networks</h2>
          <br>
          <p><img src="imgs/RNN-intro.png"></p>
        </section>

        <section>
          <h2>RNNs are tricky!</h2>
          <br>
          <p>More in later sessions.</p>
        </section>

        <section>
          <h2>Generating RNNs</h2>
          <br>
          <p><img src="imgs/RNN-generating.png"></p>
          <br>
          <p></p>
        </section>

        <section>
          <h2>Example: Caption Generation</h2>
          <br>
          <p><img src="imgs/Google-CaptionGeneration.png"></p>
          <br>
          <p>Vinyals, <i>et al.</i> (2014) </p>
        </section>

        <section>
          <h2>Encoding RNNs</h2>
          <br>
          <p><img src="imgs/RNN-encoding.png"></p>
          <br>
          <p></p>
        </section>

        <section>
          <h2>Example: Translation</h2>
          <br>
          <p><img src="imgs/Translation2-Backwards.png"></p>
          <br>
          <p>Sutskever, <i>et al.</i> (2014)</p>
        </section>

        <section>
          <h2>Stacked RNNs</h2>
          <br>
          <p><img src="imgs/RNN-stack.png"></p>
          <br>
          <p></p>
        </section>

        <section>
          <h2>Stacked RNNs (reversed layer)</h2>
          <br>
          <p><img src="imgs/RNN-stack-reverse.png"></p>
          <br>
          <p></p>
        </section>


        <section>
          <h2>Bidirectional RNNs</h2>
          <br>
          <p><img src="imgs/RNN-bidirectional.png"></p>
          <br>
          <p></p>
        </section>


        <section>
          <h2>Example: DeepSpeech</h2>
          <br>
          <p><img src="imgs/DeepSpeech.png"></p>
          <br>
          <p>(Hannun,<i>et al.</i> (2014))</p>
        </section>


        <section>
          <h2>Tree Nets!</h2>
          <p>"<i>Recursive</i> Neural Networks"</p>
        </section>

        <section>
          <p><i>Recursive</i> instead of recurrent.</p>
          <br>
          <p>Everyone mixes up the two words. A bunch of people are advocating for calling them "Tree Nets" instead.</p>
        </section>



        <section>
          <h2>Tree Nets act on Trees</h2>
          <br>
          <p><img src="imgs/TreeNet-Simple.png"></p>
          <br>
          <p></p>
        </section>


        <section>
          <h2>Different for Different Trees</h2>
          <br>
          <p><img style="width:80%" src="imgs/TreeNet-1D-B.png"></p>
          <br>
          <p></p>
        </section>

        <section>
          <h2>Example: Sentiment Analysis</h2>
          <br>
          <p><img src="imgs/Socher-SentimentTree.png"></p>
          <br>
          <p>Socher, <i>et al.</i> (2013)</p>
        </section>

        <section>
          <h2>In 3 Dimensions</h2>
          <br>
          <p><img src="imgs/TreeNet-3D-Depth1.png"></p>
          <br>
          <p></p>
        </section>

        <section>
          <h2>Deep Tree Nets</h2>
          <br>
          <p><img src="imgs/TreeNet-3D-Depth3.png"></p>
          <br>
          <p></p>
        </section>


        <section>
          <h2>Embeddings</h2>
        </section>

        <section>
          <p><img src="imgs/embed1.png"></p>
        </section>

        <section>
          <p><img src="imgs/Turian-WordTSNE.png"></p>
          <br>
          <p>(Turian, et al. 2010)</p>
        </section>

        <section>
          <p><img src="imgs/Colbert-WordTable2.png"></p>
          <br>
          <p>(Colbert et al. 2011)</p>
        </section>

        <section>
          <p><img src="imgs/embed2.png"></p>
        </section>

        <section>
          <p><img src="imgs/Colbert-WordTable2.png"></p>
          <br>
          <p>(Colbert et al. 2011)</p>
        </section>

        <section>
          <p><img src="imgs/Mikolov-GenderVecs.png"></p>
          <br>
          <p>(Mikolov et al. 2013)</p>
        </section>

        <section>
          <p><img src="imgs/Mikolov-AnalogyTable.png"></p>
          <br>
          <p>(Mikolov et al. 2013)</p>
        </section>

        <section>
          <h2>Learned Vectors</h2>
        </section>

        <section>
          <h2>Talk about Convolutions?</h2>
          <h2>Group Convolutions?</h2>
        </section>


      </div>

    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.min.js"></script>

    <script>

      // Full list of configuration options available here:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,

        theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
        transition: 'none', //Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

        // Parallax scrolling
        // parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
        // parallaxBackgroundSize: '2100px 900px',

        // Optional libraries used to extend on reveal.js
        dependencies: [
          { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
          { src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
          { src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
        ]
      });

    </script>

  </body>
</html>
