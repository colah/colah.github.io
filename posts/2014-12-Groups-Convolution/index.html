<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <title>Groups &amp; Group Convolutions - colah's blog</title>
        
        <link rel="stylesheet" href="../../fonts/Serif/cmun-serif.css" />
        <link rel="stylesheet" href="../../fonts/Serif-Slanted/cmun-serif-slanted.css" />

        <!--BOOTSTRAP-->
        <link href="../../bootstrap/css/bootstrap.min.css" rel="stylesheet">
        <!--mobile first-->
        <meta name="viewport" content="width=device-width, initial-scale=1.0">

        <!--removed html from url but still is html-->
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

        <!--font awesome-->
        <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">

        <!--fonts: allan & cardo-->
        <link href="http://fonts.googleapis.com/css?family=Droid+Serif" rel="stylesheet" type="text/css">
        <link href="http://fonts.googleapis.com/css?family=Droid+Sans" rel="stylesheet" type="text/css">

        <link href="../../css/sticky-footer-navbar.css" rel="stylesheet">

        <link href="../../css/default.css" rel="stylesheet">

        <link href="../../css/bootstrap-carousel.css" rel="stylesheet">


        <link href="../../css/inlineDisqussions.css" rel="stylesheet">

        <!--Highlight-->
        <link href="../../highlight/styles/github.css" rel="stylesheet">
        
        <link href="../../favicon.ico" rel="shortcut icon" />

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-49811703-1', 'colah.github.io');
  ga('require', 'linkid', 'linkid.js');
  ga('require', 'displayfeatures');
  ga('send', 'pageview');

</script>


    </head>

    <body>
        <div id="wrap">
            <nav class="navbar navbar-inverse navbar-static-top" role="navigation">
                <div class="container">
                    <!--Toggle header for mobile-->
                    <div class="navbar-header">
                        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                            <span class="sr-only">Toggle navigation</span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </button>
                        <a class="navbar-brand active" href="../../" id="home">colah's blog</a>
                    </div>
                    <!--normal header-->
                    <div class="navbar-collapse collapse">
                        <ul class="nav navbar-nav navbar-right">
                            <li><a href="../../"><span class="glyphicon glyphicon-pencil"></span>  Blog</a></li>
                            <li><a href="../../about.html"><span class="glyphicon glyphicon-user"></span>  About</a></li>
                            <li><a href="../../contact.html"><span class="glyphicon glyphicon-envelope"></span>  Contact</a></li>
                        </ul>
                    </div><!--/.nav-collapse -->
                </div>
            </nav>

            
            <div id="content">
                <div class="container">
                    <div class="row">
                        <div class="col-md-8">
                            <h1>Groups &amp; Group Convolutions</h1>
                            <div id="body">
                                <div class="info">
    <p style="font-family:CMSS; font-size:130%">Posted on December  8, 2014</p>
    <p style="font-family:CMS; font-style:italic"><a href="../../posts/tags/group_theory.html">group theory</a>, <a href="../../posts/tags/probability.html">probability</a>, <a href="../../posts/tags/convolution.html">convolution</a>, <a href="../../posts/tags/math.html">math</a></p>
    <!--
        by colah
    -->
</div>
</br>

<script type="text/x-mathjax-config">
MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
  var TEX = MathJax.InputJax.TeX,
      MML = MathJax.ElementJax.mml;
  var CheckDimen = function (dimen) {
    if (dimen === "" ||
        dimen.match(/^\s*([-+]?(\.\d+|\d+(\.\d*)?))\s*(pt|em|ex|mu|px|mm|cm|in|pc)\s*$/))
            return dimen.replace(/ /g,"");
    TEX.Error("Bad dimension for image: "+dimen);
  };
  TEX.Definitions.macros.img = "myImage";
  TEX.Parse.Augment({
    myImage: function (name) {
      var src = this.GetArgument(name),
          valign = CheckDimen(this.GetArgument(name)),
          width  = CheckDimen(this.GetArgument(name)),
          height = CheckDimen(this.GetArgument(name));
      var def = {src:src};
      if (valign) {def.valign = valign}
      if (width)  {def.width  = width}
      if (valign) {def.height = height}
      this.Push(this.mmlToken(MML.mglyph().With(def)));
    }
  });
});
</script>

<script type="math/tex">\newcommand{sq}[1]{~\img{img/sqF-#1.png}{-0.2em}{1.1em}{1.1em}~}</script>
<script type="math/tex">\newcommand{cards}[1]{~\img{img/card-#1.png}{-0.6em}{2.0em}{2.0em}~}</script>


<!-- $\newcommand{sq}[1]{
  ~\raise{-1pt}{
    \style{height: 15px; content: url('img/sqF-#1.png')}{
      {~\over~}\over~
    }
  }~
}
\newcommand{cards}[1]{
  ~\raise{-4pt}{
    \style{height: 23px; content: url('img/card-#1.png')}{
      {{~~\over~~}\over{~~\over~~}}\over{~~\over~~}
    }
  }~~~
}
$ -->

<h2 id="symmetry">Symmetry</h2>
<p>Consider a square. Is it symmetric? How is it symmetric? How much symmetry does it have? What kind of symmetry does it have?</p>
<p>What do those questions even mean?</p>
<p>If you ask someone, they might tell you that a square has <em>rotational symmetry</em>. If you rotate a square by 90°, it’s the same shape. Without knowing which corner was which, it would seem the exact same as it was before. You could lift it up, rotate it, and set it back down so that it covers the exact same space.</p>
<p>Let’s call this rotation transformation <span class="math">\(r\)</span>. To be precise, <span class="math">\(r\)</span> rotates a square clockwise by 90°. For example, <span class="math">\(r\sq{e} = \sq{r}\)</span>. (The “F” on the square is there to let us determine orientation and see transformations.)</p>
<p>You might also be told that a square has <em>horizontal symmetry</em> or <em>vertical symmetry</em>. You can flip a square horizontally or vertically and still have a square. Let’s focus on horizontal symmetry for now. We’ll call horizontal flips <span class="math">\(s\)</span>. <span class="math">\(s\)</span> performs a reflection across a vertical line through the middle of the square. For example, <span class="math">\(s\sq{e} = \sq{s}\)</span>.</p>
<p>We now have two transformations, <span class="math">\(r\)</span> and <span class="math">\(s\)</span>, which transform squares into another square of the same shape. It turns out that these two transformations form a kind of “basis” for all the others. By using them in some pattern, you can build the other transformations, like vertical flipping.</p>
<p>Starting with our original square <span class="math">\(\sq{e}\)</span> in the bottom left corner, the following graph shows the transformed versions generated by combining <span class="math">\(r\)</span> and <span class="math">\(s\)</span> in different ways. <span class="math">\(r\)</span> and <span class="math">\(s\)</span> are represented by arrows of different colors. <span class="math">\(r\)</span> arrows are colored blue and <span class="math">\(s\)</span> arrows are colored red.</p>
<div class="bigcenterimgcontainer">
<img src="img/sqF-cayley.png" alt style>
</div>
<div class="spaceafterimg">

</div>
<p>We can use the graph to investigate what happens if we perform a sequence of transformations. For example, what happens if we rotate, flip and then rotate again? Well, we start at our original square, <span class="math">\(\sq{e}\)</span>, and trace: <span class="math">\(\sq{e} \xrightarrow{r} \sq{r} \xrightarrow{s} \sq{r3s} \xrightarrow{r} \sq{s}\)</span>. In the end, we’re left with just horizontally flipped version of the original, <span class="math">\(s\sq{e} = \sq{s}\)</span>. If we want to express this surprising fact, we can use multiplication like notation: <span class="math">\(rsr \sq{e} = s \sq{e}\)</span>.</p>
<p>If we want to think about our graph a bit more abstractly, we can represent all the squares as the original square transformed by <span class="math">\(r\)</span> and <span class="math">\(s\)</span>. For example, <span class="math">\(\sq{r2s} = r^2s\sq{e}\)</span>.</p>
<div class="bigcenterimgcontainer">
<img src="img/sqF-cayley-factor.png" alt style>
</div>
<div class="spaceafterimg">

</div>
<p>Here, <span class="math">\(e\)</span> is the <em>identity transformation</em>, which doesn’t transform the object at all. For example <span class="math">\(e\sq{e} = \sq{e}\)</span>. (Why have <span class="math">\(e\)</span>, if it doesn’t do anything? It’s a lot like having the number zero.)</p>
<p>We can go a bit further. The original square, <span class="math">\(\sq{e}\)</span>, seems a bit unnecessary in <span class="math">\(rsr \sq{e} = s \sq{e}\)</span>. Why not just say <span class="math">\(rsr = s\)</span>? We can just drop the factored out <span class="math">\(\sq{e}\)</span>, both in equations and our graph.</p>
<div class="bigcenterimgcontainer">
<img src="img/sqF-cayley-symb.png" alt style>
</div>
<div class="spaceafterimg">

</div>
<p>Now, here’s the essential realization: <span class="math">\(r\)</span> and <span class="math">\(s\)</span> could have been other things and we would have had the exact same graph. <span class="math">\(r\)</span> could have been rotating 90° <em>counter</em>clockwise. <span class="math">\(s\)</span> could have been vertical flips. Or we could have been transforming an entirely different kind of object. All that matters is the relationship between <span class="math">\(r\)</span> and <span class="math">\(s\)</span>, how they interact. What we saw with the squares was just one particular way this graph, this abstract pattern, could appear in the real world.</p>
<p>Mathematicians call these abstract patterns <em>groups</em>. There is an entire field of math dedicated to them. Connections between a group and an object like the square are called <em>group actions</em>.</p>
<h2 id="but-what-is-a-group">But… What is a group?</h2>
<p>Not all graphs are groups. Only a very special kind of graph is. (We won’t give a formal definition here, but we will get a good feel for it.)</p>
<p>Firstly, the graph is directed (the edges are arrows) and has colored edges. At every vertex, exactly one arrow of a given color comes out and one goes in.</p>
<p>But the key property of these graphs is more subtle. We created our graph by starting with an original square, <span class="math">\(\sq{e}\)</span>. But what if we said the original square was <span class="math">\(\sq{s} = s\sq{e}\)</span>?</p>
<div class="bigcenterimgcontainer">
<img src="img/sqF-cayley-alt.png" alt style>
</div>
<div class="spaceafterimg">

</div>
<p>Which position we say is the “initial” position is arbitrary. No matter which position you think of as the initial one, the graph is the same. The graph is perfectly symmetrical, in some sense.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> Imagine that the edges are paths of different color you can walk on, and you’re standing on one of the nodes: from your perspective the graph is the same no matter which node you’re standing on. No matter which node you’re on, taking a red path, a blue path, and then a red path and then a blue path again will bring you back to where you started.</p>
<p>In Euclidean space, we reason about points by their relative position to an origin. Similarly, in our group, we pick some origin (eg. <span class="math">\(\sq{e}\)</span>) and talk about points by their relative positions. We call these relative positions (such as <span class="math">\(r\)</span>, <span class="math">\(s\)</span>, or <span class="math">\(r^3s\)</span>), the <em>elements</em> of the group.</p>
<p>Just like we can add difference vectors of points, we can “add” elements of a group together. It isn’t <em>actually</em> addition, of course, but it is a natural way to combine elements of the group. Sometimes we talk about it by analogy with addition and write combining two elements <span class="math">\(a\)</span> and <span class="math">\(b\)</span> as <span class="math">\(a+b\)</span>, while other times we make analogies to multiplication and write <span class="math">\(a\cdot b\)</span>.</p>
<p>“Adding” or “multiplying” two group elements is actually quite similar to vector addition. We decide that one point on the graph is our identity element (the original position), and find the two elements we want to multiply, <span class="math">\(a\)</span> and <span class="math">\(b\)</span>. We pick paths from the identity to <span class="math">\(a\)</span> and <span class="math">\(b\)</span>. Then we stick the <span class="math">\(a\)</span> path on to the end of <span class="math">\(b\)</span>, to bring us to <span class="math">\(a+b\)</span> or <span class="math">\(a\cdot b\)</span> (depending on the chosen notation).</p>
<div class="bigcenterimgcontainer">
<img src="img/sqF-add.png" alt style>
</div>
<div class="spaceafterimg">

</div>
<h2 id="the-algebraic-perspective">The Algebraic Perspective</h2>
<p><em>(This section is optional.)</em></p>
<p>The above is almost unrecognizable as group theory, from a traditional perspective. Usually, we think of groups as a kind of abstraction.</p>
<p>There are lots of kinds of mathematical objects and, as you look at more of them, one beings to see patterns. For example, in arithmetic, we see <span class="math">\(a\!\cdot\!(b+c) ~=~ a\!\cdot\! b ~+~ a\!\cdot\! c\)</span> and in set theory we see <span class="math">\(A\cap (B \cup C) = A\cap B ~\cup~ A\cap C\)</span>. There are many other examples of this pattern, and many other patterns.</p>
<p>One also notices that many important results are true for a broad class of objects, and they’re all true for the same reason. They’re true because all the objects observe a particular pattern. Knowing that a mathematical object obeys that pattern is sufficient to prove the result holds.</p>
<p>So, we formalize those patterns into what we call <em>mathematical structures</em>.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> There’s <strong>a lot</strong> of them, and you can find a <a href="http://en.wikipedia.org/wiki/List_of_algebraic_structures">very long list of algebraic ones on wikipedia</a>. We can study a mathematical structure and prove results that hold for any instance of that structure. (Programmers and computer scientists can see this as making mathematics polymorphic.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>)</p>
<p>We can now give the classical definition of a group. Don’t worry too much if you have trouble following.</p>
<p><strong>Definition:</strong> A group <span class="math">\(G = (S, ~\cdot~)\)</span> is a set <span class="math">\(S\)</span> equipped with a binary operation <span class="math">\((~\cdot~)\)</span>, a function mapping pairs of group elements to group elements, with the following properties:</p>
<ul>
<li>There exists an identity element, <span class="math">\(e \in S\)</span>, such that <span class="math">\(e\cdot x ~=~ x \cdot e ~=~ x\)</span> for all <span class="math">\(x \in S\)</span>.</li>
<li>For all elements <span class="math">\(x \in S\)</span>, there exists an inverse element <span class="math">\(x^{-1} \in S\)</span> such that <span class="math">\(x\cdot x^{-1} = x^{-1}\cdot x = e\)</span>.</li>
<li>The operation <span class="math">\((~\cdot~)\)</span> is associative. That is, <span class="math">\((a\cdot b)\cdot c ~=~ a\cdot (b\cdot c)\)</span> for all <span class="math">\(a,b,c \in S\)</span>,</li>
</ul>
<p>Why those rules? Why not more or less? Well, we could define a group to have more or less requirements. If it was weaker, had less requirements, more kinds of objects would be groups and the results we prove about groups would be more broadly applicable. If it was stronger, had more requirements, we would be talking about a more specific kind of object and could prove more about them. In mathematics one often balances generality and specificity like this.</p>
<p>Mathematicians study both weaker and stronger versions of groups. But, somehow, groups are special. They aren’t too hot, they aren’t too cold: they’re just right.</p>
<p>This might seem kind of arbitrary. Why should these particular rules be a particularly good collection? One thing that I find very helpful and motivating is realizing that they’re equivalent to the requirements we made when we were thinking of groups as graphs. Identity corresponds to there being a starting point, inverses to being able to go backwards on arrows, and associativity is equivalent to the perfect symmetry of the graph.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></p>
<h2 id="a-group-from-three-cards">A Group from Three Cards</h2>
<p>Consider three cards, <span class="math">\(\cards{123}\)</span>. There are some transformations that are natural to apply to them. We’ll call the operation of switching the first two cards <span class="math">\((12)\)</span>. Similarly, we’ll call the operation of switching the second cards <span class="math">\((23)\)</span>. So,</p>
<p><span class="math">\[(12)\cards{123} = \cards{213} ~~~~~~~~~~~~~~~~~~~~~~~~ (23)\cards{123} = \cards{132}\]</span></p>
<p>Together, these two operations generate a group, the <a href="http://en.wikipedia.org/wiki/Symmetric_group">Symmetric Group</a> on 3 symbols, <span class="math">\(S_3\)</span>.</p>
<div class="bigcenterimgcontainer">
<img src="img/card-cayley.png" alt style>
</div>
<div class="spaceafterimg">

</div>
<p>Each group element is a particular way to rearrange the cards, a permutation.</p>
<h2 id="shuffling-cards">Shuffling Cards</h2>
<p>One interesting thing to think about is shuffling. When we shuffle cards, we try to put them in a random ordering, a random permutation. This means we create a probability distribution over the group.</p>
<p>Ideally, our shuffle would give us a uniform distribution – every permutation would be equally likely. But we can easily imagine an imperfect shuffle, where some permutations are more likely than others.</p>
<div class="centerimgcontainer">
<img src="img/card-shuffle1.png" alt style>
</div>
<div class="spaceafterimg">

</div>
<p>Of course, if the first shuffle doesn’t randomize them, we can shuffle again!</p>
<div class="centerimgcontainer">
<img src="img/card-shuffle2.png" alt style>
</div>
<div class="spaceafterimg">

</div>
<p>Generally, repeated shuffles will cause probability mass to diffuse, bringing us closer to the uniform distribution.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></p>
<p>This should feel similar to the falling ball example in the <a href="../2014-07-Understanding-Convolutions/">Understanding Convolutions post</a>. Fundamentally, they are the same thing: convolution.</p>
<div class="centerimgcontainer">
<img src="img/FallingBall.png" alt style>
</div>
<div class="spaceafterimg">

</div>
<h2 id="group-convolutions">Group Convolutions</h2>
<p>The earlier visualizations of probability distributions on the permutations were kind of messy. The natural way to visualize it is on the Cayley diagram!</p>
<p>Let’s consider a very simple probability distribution. 40% of the time we apply the operation <span class="math">\((12)\)</span>, permuting our cards to <span class="math">\(\cards{213}\)</span>. 60% of the time we apply <span class="math">\((23)\)</span>, permuting our cards to <span class="math">\(\cards{132}\)</span>. That’s a terrible shuffle, but it is easy to think about.</p>
<div class="centerimgcontainer">
<img src="img/cayley-prob.png" alt style>
</div>
<div class="spaceafterimg">

</div>
<p>To be a bit more explicit, let’s picture us as starting with all the probability density on the unpermuted cards <span class="math">\(\cards{123}\)</span> (i.e. the identity), and then we apply our very silly shuffle.</p>
<p>When we shuffle, we sample this distribution, getting some permutation <span class="math">\(a\)</span> with probability <span class="math">\(f(a)\)</span>.</p>
<div class="bigcenterimgcontainer">
<img src="img/card-conv1.png" alt style>
</div>
<div class="spaceafterimg">

</div>
<p>What happens when we shuffle a second time?</p>
<p>Well, the first time we shuffled, we got a permutation <span class="math">\(a\)</span> with probability <span class="math">\(f(a)\)</span>. The second time we shuffle, we will get another permutation <span class="math">\(b\)</span> with probability <span class="math">\(g(b)\)</span>. These two actions happen with probability <span class="math">\(f(a)g(b)\)</span> and result is a permutation <span class="math">\(c = b\cdot a\)</span>.</p>
<div class="bigcenterimgcontainer">
<img src="img/card-conv-steps.png" alt style>
</div>
<div class="spaceafterimg">

</div>
<p>To get the actual probability of <span class="math">\(c\)</span>, though, it is not sufficient to just look at one pair of permutations that bring us to <span class="math">\(c\)</span>. Instead, we need to sum over all possible pairs of permutations. This is the convolution of <span class="math">\(g\)</span> and <span class="math">\(f\)</span> (like in function composition, the right side goes first).</p>
<p><span class="math">\[(g\ast f)(c) = \sum_{b \cdot a = c} g(b)f(a)\]</span></p>
<p>Substituting <span class="math">\(b = ca^{-1}\)</span>, we get:</p>
<p><span class="math">\[(g\ast f)(c) = \sum_{a} g(ca^{-1})f(a)\]</span></p>
<p>This can be nicely thought of as a sum over the intermediate permutations, <span class="math">\(a\)</span>, looking at the probability of that intermediate permutation, and the probability of the permutation necessary to bring us to <span class="math">\(c\)</span> from there.</p>
<div class="bigcenterimgcontainer">
<img src="img/card-conv2.png" alt style>
</div>
<div class="spaceafterimg">

</div>
<p>Alternatively, we can substitute <span class="math">\(a = b^{-1}c\)</span> to get:</p>
<p><span class="math">\[(g\ast f)(c) = \sum_{b} g(b)f(b^{-1}c)\]</span></p>
<p>The traditional definition of group convolution. (If you let the group operation be addition, this is the normal definition of convolution.)</p>
<h2 id="further-generalizations-of-convolution">Further Generalizations of Convolution</h2>
<p><em>(This section is optional and assumes a stronger background than the rest of the article. Less mathematically inclined readers might wish to skip this section.)</em></p>
<p>The traditional definition of convolution requires that you be able to take inverses, and multiply every element by every other element. This means you need to be working on a group, or perhaps a quasigroup.</p>
<p>But if you switch to the definition <span class="math">\((g\ast f)(c) = \sum_{b \cdot a = c} g(b)f(a)\)</span>, which seems much more natural, convolution makes sense on just about any algebraic structure with a binary operator. Certainly, you can talk about convolutions on monoids, groupoids, and categories. As far as I can tell, no one’s really considered these.<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a></p>
<p>One cute thing about this is that convolution often inherits the algebraic properties of the domains of the functions being convolved. For example, if you convolve functions on associative domains, the convolution operation is associative:</p>
<p><span class="math">\[((A\ast B) \ast C)(x) = \sum_{a \cdot b \cdot c = x} A(a)B(b)C(c) = (A\ast (B \ast C))(x)\]</span></p>
<p>Similarly, if the domain is commutative, so is convolution. And if it has identity, so does convolution. Sadly, convolution doesn’t get inverses if the domain has inverses, so the parallel breaks down at Abelian monoids.</p>
<p>With the math working out so nicely, you might wonder if there’s any reason one might actually use these. Well, convolution on monoids seems natural in cases where you “can’t go backwards”. And convolution on categories allows for a kind of state. In fact, I think you could very naturally describe probabilistic automaton in terms of category convolutions.</p>
<h2 id="conclusion">Conclusion</h2>
<p>This essay takes an unusual perspective on group theory. Cayley diagrams have been around for a long time, but, as far as I know, taking them seriously as an approach to group theory, as a kind of foundation, is a recent idea, engineered by Nathan Carter in his book <em>Visual Group Theory</em>. Interested readers are encouraged to look at his book.</p>
<p>Group convolutions provide elegant language for talking about lots of situations involving probability. But, since this is a series of blog posts on <em>convolutional neural networks</em>, you may suspect that I have other interests in them. Well, you guessed correctly. Group convolutions naturally extend convolutional neural networks, with everything fitting together extremely nicely. Since convolutional neural networks are one of the most powerful tools in machine learning right now, that’s pretty interesting. In our next post, we will explore these networks.</p>
<h2 id="next-posts-in-this-series">Next Posts in this Series</h2>
<p>This post is part of a series on convolutional neural networks and their generalizations. The first two posts will be review for those familiar with deep learning, while later ones should be of interest to everyone. To get updates, subscribe to my <a href="../../rss.xml">RSS feed</a>!</p>
<p>Please comment below or on the side. Pull requests can be made on <a href="https://github.com/colah/colah.github.io">github</a>.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>I’m grateful to Yomna Nasser, Harry de Valence, Sam Eisenstat, and Sebastian Zany for taking the time to read and comment on draft version of this post – their feedback improved it a lot!</p>
<p>I’m also grateful to Guillaume Alain, Eliana Lorch, Dario Amodei, Aaron Courville, Yoshua Bengio, and Michael Nielsen for discussion of group convolution and its potential applications to neural networks.</p>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Note that the graph embedding isn’t necessarily symmetrical.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Usually people talk about <em>algebraic structures</em>, abstract mathematical structures from algebra. There are similar abstract mathematical structures in other areas, particularly in analysis. For example: <a href="http://en.wikipedia.org/wiki/Metric_space">metric spaces</a>, <a href="http://en.wikipedia.org/wiki/Topological_space">topological spaces</a> and <a href="http://en.wikipedia.org/wiki/Measure_(mathematics)">measure spaces</a>. However, these are rarely lumped together in the way that algebraic structures are.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>This is actually a very deep analogy. In programming, we often try to write polymorphic functions that can act on many kinds of objects. In mathematics, we’re trying to make polymorphic proofs that can operate on different kinds of mathematical object. The <a href="http://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence">Curry–Howard correspondence</a> formalizes this connection between programs and proofs.</p>
<p>(Some programming languages, like Haskell, even have implementations of common algebraic structures as classes!)</p>
<p>It’s also worth noting that, just as most approaches to polymorphism in programming give us subclasses and superclasses, algebraic structures also kind of have “sub-structures” and “super-structures”.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>The associativity part is a bit tricky to see, especially because we never rigorously defined the “perfect symmetry” of our “group graphs.”</p>
<p>One definition is that, given a loop originating at <span class="math">\(e\)</span> on the graph, <span class="math">\(((bc)d)... = e\)</span>, that same sequence is also a loop if it starts at a point <span class="math">\(a\)</span>, that is <span class="math">\((((ab)c)d)... = a\)</span>. It’s pretty straightforward to see that this follows from associativity, but what about the other direction?</p>
<p>Well, we want to prove for all <span class="math">\(a,b,c\)</span>, that, <span class="math">\(a(bc) = (ab)c\)</span>. Let <span class="math">\(d = (bc)^{-1}\)</span>, the reverse of the path to <span class="math">\(bc\)</span>. Then <span class="math">\((bc)d = e\)</span> is a loop. By the graph symmetry, <span class="math">\(((ab)c)d = a\)</span>. We now right-mulitply by <span class="math">\(d^{-1} = (bc)\)</span> to get <span class="math">\((ab)c = a(bc)\)</span>, which is associativity.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>How many times do you have to shuffle a deck of cards to make it truly random? This question was explored by the mathematician Persi Diaconis.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>I can’t really find instances of people talking about these convolutions as independent things, but the operation seems to be implicitly constructed in objects built to study these structures. Just as multiplication in <a href="http://en.wikipedia.org/wiki/Group_ring">group rings</a> is group convolution, multiplication in <a href="http://en.wikipedia.org/wiki/Monoid_ring">monoid rings</a> is monoid convolution, multiplication in <a href="http://en.wikipedia.org/wiki/Groupoid_algebra">groupoid algebras</a> is groupoid convolution, and multiplication in <a href="http://en.wikipedia.org/wiki/Categorical_algebra">categorical algebras</a> is category convolution.<a href="#fnref6">↩</a></p></li>
</ol>
</section>

<div id="disqus_thread"></div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>

<script src="../../js/inlineDisqussions.js"></script>
<script src="../../js/disqus.js"></script>
                            </div>
                        </div>
                        <div class="col-md-4" id="toc-wrapper">
                        </div>
                    </div>
                </div>
            </div>
        

            <div id="footer">
                <div class="container">
                    Subscribe to the <a href="../../rss.xml">RSS feed</a>.
                    </br>
                    Built by <a href="https://github.com/oinkina">Oinkina</a> with
                    <a href="http://jaspervdj.be/hakyll">Hakyll</a> 
                    using <a href="http://getbootstrap.com/">Bootstrap</a>, 
                    <a href="http://www.mathjax.org/">MathJax</a>, and
                    <a href="http://disqus.com/">Disqus</a>.
                </div>
            </div>
        </div>

    <!-- jQuery-->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>

    <script src="../../bootstrap/js/bootstrap.min.js"></script>

    <script src="../../highlight/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    <script src="../../js/footnotes.js"></script>
    <script src="../../js/bootstrap-carousel.js"></script>
    <script src="../../js/inlineDisqussions.js"></script>
    <script src="../../js/toc.js"></script>


<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

    <noscript>Enable JavaScript for footnotes, Disqus comments, and other cool stuff.</noscript>

    </body>

</html>
